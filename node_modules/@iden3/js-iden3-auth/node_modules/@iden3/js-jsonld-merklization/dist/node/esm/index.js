// src/lib/constants.ts
var MerklizationConstants = Object.freeze({
  ERRORS: {
    CONTEXT_NOT_DEFINED: new Error("error: context not defined on the object"),
    PARSED_CONTEXT_IS_NULL: new Error("error: parsed context is null"),
    TERM_IS_NOT_DEFINED: new Error("error: term is not defined"),
    NO_ID_ATTR: new Error("error: no @id attribute is defined"),
    CTX_TYP_IS_EMPTY: new Error("error: ctx type is empty"),
    FIELD_PATH_IS_EMPTY: new Error("error: filed path is empty"),
    UNEXPECTED_ARR_ELEMENT: new Error("error: unexpected array elements"),
    INVALID_REFERENCE_TYPE: new Error("error: invalid reference type"),
    MULTIPLE_PARENTS_FOUND: new Error("error: multiple parents found"),
    PARENT_NOT_FOUND: new Error("error: parent not found"),
    GRAPH_NOT_FOUND: new Error("error: graph not found"),
    QUAD_NOT_FOUND: new Error("error: quad not found"),
    MT_VALUE_INCORRECT_TYPE: new Error("error: incorrect type")
  },
  DEFAULT_GRAPH_NODE_NAME: "@default",
  DEFAULT_GRAPH_TERM_TYPE: "DefaultGraph",
  QUADS_FORMAT: "application/n-quads",
  DIGITS_ONLY_REGEX: /^\d+$/,
  Q: BigInt("21888242871839275222246405745257275088548364400416034343698204186575808495617")
});

// src/lib/poseidon.ts
import { poseidon } from "@iden3/js-crypto";
var PoseidonHasher = class {
  constructor(_hasher = poseidon) {
    this._hasher = _hasher;
  }
  async hash(inp) {
    return this._hasher.hash(inp);
  }
  async hashBytes(b) {
    return this._hasher.hashBytes(b);
  }
  prime() {
    return MerklizationConstants.Q;
  }
};
var DEFAULT_HASHER = new PoseidonHasher();

// src/lib/types/types.ts
var canonicalDouble = (v) => v.toExponential(15).replace(/(\d)0*e\+?/, "$1E");

// src/lib/mt-value.ts
import { Temporal as Temporal2 } from "@js-temporal/polyfill";

// src/lib/utils.ts
import { Temporal } from "@js-temporal/polyfill";
function getGraphName(q) {
  if (!q.graph.value) {
    return MerklizationConstants.DEFAULT_GRAPH_NODE_NAME;
  }
  if (q.graph.termType !== "BlankNode") {
    throw new Error("graph node is not of BlankNode type");
  }
  return q.graph.value;
}
var sortArr = (arr) => {
  return arr.sort((a, b) => {
    if (a < b) {
      return -1;
    }
    if (a > b) {
      return 1;
    }
    return 0;
  });
};
var byteEncoder = new TextEncoder();
var validateValue = (val) => {
  switch (typeof val) {
    case "boolean":
    case "string":
    case "bigint":
    case "number":
      return;
    case "object":
      if (val instanceof Temporal.Instant) {
        return;
      }
  }
  throw new Error(
    `unexpected value type ${typeof val}, expected boolean | number | Temporal.Instant | string`
  );
};
var minMaxFromPrime = (prime) => {
  const max = prime / 2n;
  const min = max - prime + 1n;
  return { min, max };
};
function minMaxByXSDType(xsdType, prime) {
  switch (xsdType) {
    case "http://www.w3.org/2001/XMLSchema#positiveInteger" /* PositiveInteger */:
      return { min: 1n, max: prime - 1n };
    case "http://www.w3.org/2001/XMLSchema#nonNegativeInteger" /* NonNegativeInteger */:
      return { min: 0n, max: prime - 1n };
    case "http://www.w3.org/2001/XMLSchema#integer" /* Integer */:
      return minMaxFromPrime(prime);
    case "http://www.w3.org/2001/XMLSchema#negativeInteger" /* NegativeInteger */:
      return { min: minMaxFromPrime(prime).min, max: -1n };
    case "http://www.w3.org/2001/XMLSchema#nonPositiveInteger" /* NonPositiveInteger */:
      return { min: minMaxFromPrime(prime).min, max: 0n };
    default:
      throw new Error(`unsupported XSD type: ${xsdType}`);
  }
}
var convertStringToXsdValue = (dataType, valueStr, maxFieldValue) => {
  switch (dataType) {
    case "http://www.w3.org/2001/XMLSchema#boolean" /* Boolean */:
      switch (valueStr) {
        case "false":
        case "0":
          return false;
        case "true":
        case "1":
          return true;
        default:
          throw new Error("incorrect boolean value");
      }
    case "http://www.w3.org/2001/XMLSchema#integer" /* Integer */:
    case "http://www.w3.org/2001/XMLSchema#nonNegativeInteger" /* NonNegativeInteger */:
    case "http://www.w3.org/2001/XMLSchema#nonPositiveInteger" /* NonPositiveInteger */:
    case "http://www.w3.org/2001/XMLSchema#negativeInteger" /* NegativeInteger */:
    case "http://www.w3.org/2001/XMLSchema#positiveInteger" /* PositiveInteger */:
      const int = BigInt(valueStr);
      const { min, max } = minMaxByXSDType(dataType, maxFieldValue);
      if (int > max) {
        throw new Error(`integer exceeds maximum value: ${int}`);
      }
      if (int < min) {
        throw new Error(`integer is below minimum value: ${int}`);
      }
      return int;
    case "http://www.w3.org/2001/XMLSchema#dateTime" /* DateTime */: {
      if (isNaN(Date.parse(valueStr))) {
        throw new Error(`error: error parsing time string ${valueStr}`);
      }
      const dateRegEx = /^\d{4}-\d{2}-\d{2}$/;
      if (dateRegEx.test(valueStr)) {
        return Temporal.Instant.from(new Date(valueStr).toISOString());
      }
      return Temporal.Instant.from(valueStr);
    }
    case "http://www.w3.org/2001/XMLSchema#double" /* Double */:
      return canonicalDouble(parseFloat(valueStr));
    default:
      return valueStr;
  }
};
var convertAnyToString = (v, datatype) => {
  const isDoubleType = datatype === "http://www.w3.org/2001/XMLSchema#double" /* Double */;
  switch (typeof v) {
    case "string":
      return isDoubleType ? canonicalDouble(parseFloat(v)) : v;
    case "boolean":
      return `${v}`;
    case "number": {
      return isDoubleType ? canonicalDouble(v) : `${v}`;
    }
    default:
      throw new Error("unsupported type");
  }
};

// src/lib/mt-value.ts
var bytesEncoder = new TextEncoder();
var MtValue = class _MtValue {
  constructor(value, h = DEFAULT_HASHER) {
    this.value = value;
    this.h = h;
  }
  isString() {
    return typeof this.value === "string";
  }
  asString() {
    if (!this.isString()) {
      throw MerklizationConstants.ERRORS.MT_VALUE_INCORRECT_TYPE;
    }
    return this.value.toString();
  }
  isTime() {
    return this.value instanceof Temporal2.Instant;
  }
  asTime() {
    if (!this.isTime()) {
      throw MerklizationConstants.ERRORS.MT_VALUE_INCORRECT_TYPE;
    }
    return this.value;
  }
  isNumber() {
    return typeof this.value === "number";
  }
  asNumber() {
    if (!this.isNumber()) {
      throw MerklizationConstants.ERRORS.MT_VALUE_INCORRECT_TYPE;
    }
    return this.value;
  }
  isBool() {
    return typeof this.value === "boolean";
  }
  asBool() {
    if (!this.isBool()) {
      throw MerklizationConstants.ERRORS.MT_VALUE_INCORRECT_TYPE;
    }
    return this.value;
  }
  mtEntry() {
    return _MtValue.mkValueMtEntry(this.h, this.value);
  }
  isBigInt() {
    return typeof this.value === "bigint";
  }
  asBigInt() {
    if (!this.isBigInt()) {
      throw MerklizationConstants.ERRORS.MT_VALUE_INCORRECT_TYPE;
    }
    return this.value;
  }
  static mkValueMtEntry = (h, v) => {
    switch (typeof v) {
      case "number":
        return _MtValue.mkValueInt(h, v);
      case "string":
        return _MtValue.mkValueString(h, v);
      case "boolean":
        return _MtValue.mkValueBool(h, v);
      case "bigint":
        return _MtValue.mkValueBigInt(h, v);
      default: {
        if (v instanceof Temporal2.Instant) {
          return _MtValue.mkValueTime(h, v);
        }
        throw new Error(`error: unexpected type ${typeof v}`);
      }
    }
  };
  static async mkValueInt(h, v) {
    if (v >= 0) {
      return BigInt(v);
    }
    return h.prime() + BigInt(v);
  }
  static mkValueUInt = (h, v) => {
    return BigInt.asUintN(64, v);
  };
  static mkValueBool = (h, v) => {
    if (v) {
      return h.hash([BigInt.asIntN(64, BigInt(1))]);
    }
    return h.hash([BigInt.asIntN(64, BigInt(0))]);
  };
  static mkValueString = (h, v) => {
    return h.hashBytes(bytesEncoder.encode(v));
  };
  static mkValueTime = async (h, v) => {
    return this.mkValueInt(h, v.epochNanoseconds);
  };
  static mkValueBigInt = async (h, v) => {
    const prime = h.prime();
    if (v >= prime) {
      throw new Error(`value is too big: ${v}`);
    }
    if (v < 0n) {
      const { min } = minMaxFromPrime(prime);
      if (v < min) {
        throw new Error(`value is too small: ${v}`);
      }
      return v + prime;
    }
    return v;
  };
};

// src/lib/merklizer.ts
import {
  compact
} from "jsonld";
import { Merkletree as Merkletree2 } from "@iden3/js-merkletree";

// src/lib/rdf-dataset.ts
import { Parser } from "n3";
import { canonize } from "jsonld";

// src/lib/dataset-idx.ts
var DatasetIdx = class {
  constructor(graphName, idx) {
    this.graphName = graphName;
    this.idx = idx;
  }
  toString() {
    return `${this.graphName}:${this.idx}`;
  }
};

// src/lib/ref-tp.ts
var RefTp = class _RefTp {
  constructor(tp, val) {
    this.tp = tp;
    this.val = val;
  }
  toString() {
    return JSON.stringify(this);
  }
  static getRefFromQuad(n) {
    if (n.termType === "NamedNode" /* IRI */) {
      return new _RefTp("NamedNode" /* IRI */, n.value);
    }
    if (n.termType === "BlankNode" /* BlankNode */) {
      return new _RefTp("BlankNode" /* BlankNode */, n.value);
    }
    return new _RefTp("Undefined" /* Undefined */, "");
  }
};

// src/loaders/jsonld-loader.ts
import { parseLinkHeader } from "jsonld/lib/util";
import { LINK_HEADER_CONTEXT } from "jsonld/lib/constants";
import JsonLdError from "jsonld/lib/JsonLdError";
import { prependBase } from "jsonld/lib/url";
var JsonLDLoader = class {
  async loadDocument(url, redirects = []) {
    const isHttp = url.startsWith("http:");
    const isHttps = url.startsWith("https:");
    if (!isHttp && !isHttps) {
      throw new JsonLdError(
        'URL could not be dereferenced; only "http" and "https" URLs are supported.',
        "jsonld.InvalidUrl",
        { code: "loading document failed", url }
      );
    }
    let alternate = null;
    const { res, body } = await _fetch({ url });
    const doc = { contextUrl: void 0, documentUrl: url, document: body || null };
    if (res.status >= 400) {
      throw new JsonLdError(
        `URL "${url}" could not be dereferenced: ${res.statusText}`,
        "jsonld.InvalidUrl",
        {
          code: "loading document failed",
          url,
          httpStatusCode: res.status
        }
      );
    }
    const link = res.headers.get("link");
    let location = res.headers.get("location");
    const contentType = res.headers.get("content-type");
    if (link && contentType !== "application/ld+json" && contentType !== "application/json") {
      const linkHeaders = parseLinkHeader(link);
      const linkedContext = linkHeaders[LINK_HEADER_CONTEXT];
      if (Array.isArray(linkedContext)) {
        throw new JsonLdError(
          "URL could not be dereferenced, it has more than one associated HTTP Link Header.",
          "jsonld.InvalidUrl",
          { code: "multiple context link headers", url }
        );
      }
      if (linkedContext) {
        doc.contextUrl = linkedContext.target;
      }
      alternate = linkHeaders.alternate;
      if (alternate && alternate["type"] == "application/ld+json" && !(contentType || "").match(/^application\/(\w*\+)?json$/)) {
        location = prependBase(url, alternate["target"]);
      }
    }
    if ((alternate || res.status >= 300 && res.status < 400) && location) {
      if (redirects.length === -1) {
        throw new JsonLdError(
          "URL could not be dereferenced; there were too many redirects.",
          "jsonld.TooManyRedirects",
          {
            code: "loading document failed",
            url,
            httpStatusCode: res.status,
            redirects
          }
        );
      }
      if (redirects.indexOf(url) !== -1) {
        throw new JsonLdError(
          "URL could not be dereferenced; infinite redirection was detected.",
          "jsonld.InfiniteRedirectDetected",
          {
            code: "recursive context inclusion",
            url,
            httpStatusCode: res.status,
            redirects
          }
        );
      }
      redirects.push(url);
      const nextUrl = new URL(location, url).href;
      return this.loadDocument(nextUrl, redirects);
    }
    redirects.push(url);
    return doc;
  }
};
var ipfsMethodCat = "cat";
function normalizeIPFSNodeURL(ipfsNodeURL, apiMethod) {
  const apiSuffix = "/api/v0";
  while (ipfsNodeURL.endsWith("/")) {
    ipfsNodeURL = ipfsNodeURL.slice(0, -1);
  }
  if (!ipfsNodeURL.endsWith(apiSuffix)) {
    ipfsNodeURL += apiSuffix;
  }
  return ipfsNodeURL + "/" + apiMethod;
}
function trimRightSlash(url) {
  while (url.endsWith("/")) {
    url = url.slice(0, -1);
  }
  return url;
}
function trimLeftSlash(url) {
  while (url.startsWith("/")) {
    url = url.slice(1);
  }
  return url;
}
function buildIpfsGatewayURL(ipfsGatewayURL, documentURL) {
  return trimRightSlash(ipfsGatewayURL) + "/ipfs/" + trimLeftSlash(documentURL);
}
async function loadIPFS(url, ipfsNodeURL = void 0, ipfsGatewayURL = void 0) {
  const documentURL = ipfsURLPrefix + url;
  if (!ipfsNodeURL && !ipfsGatewayURL) {
    throw new JsonLdError("IPFS is not configured", "jsonld.IPFSNotConfigured", {
      code: "loading document failed",
      url: documentURL
    });
  }
  if (ipfsNodeURL) {
    return await loadFromIPFSNode(url, ipfsNodeURL);
  } else {
    return await loadFromIPFSGateway(url, ipfsGatewayURL);
  }
}
async function loadFromIPFSNode(url, ipfsNodeURL) {
  const catRequestURL = new URL(normalizeIPFSNodeURL(ipfsNodeURL, ipfsMethodCat));
  catRequestURL.searchParams.append("arg", url);
  const { res, body } = await _fetch({ url: catRequestURL, method: "POST" });
  if (res.status != 200) {
    throw new Error(`Error calling IPFS node: [${res.status}] ${res.statusText}
${body}`);
  }
  return {
    contextUrl: void 0,
    document: body || null,
    documentUrl: ipfsURLPrefix + url
  };
}
async function loadFromIPFSGateway(url, ipfsGatewayURL = void 0) {
  if (!ipfsGatewayURL) {
    throw new JsonLdError("IPFS gateway is not configured", "jsonld.IPFSNotConfigured", {
      code: "loading document failed",
      url: ipfsURLPrefix + url
    });
  }
  const loader = new JsonLDLoader();
  const document = await loader.loadDocument(buildIpfsGatewayURL(ipfsGatewayURL, url), []);
  document.contextUrl = void 0;
  document.documentUrl = ipfsURLPrefix + url;
  return document;
}
async function _fetch({ url, method }) {
  const options = {};
  if (typeof method !== "undefined") {
    options["method"] = method;
  }
  try {
    url = new URL(url);
    if (url.username && url.password) {
      options["headers"] = {
        ...options["headers"] ?? {},
        authorization: `Basic ${btoa(url.username + ":" + url.password)}`
      };
      url = removeCredentialsFromURL(url);
    }
    const res = await fetch(url, options);
    if (res.status >= 300 && res.status < 400) {
      return { res, body: null };
    }
    const text = await res.text();
    if (text && text.length > 0 && text.startsWith("{")) {
      return { res, body: JSON.parse(text) };
    }
    return { res, body: text };
  } catch (e) {
    if (e instanceof Error && "response" in e) {
      return { res: e.response, body: null };
    }
    throw new JsonLdError(
      "URL could not be dereferenced, an error occurred.",
      "jsonld.LoadDocumentError",
      { code: "loading document failed", url, cause: e }
    );
  }
}
function removeCredentialsFromURL(url) {
  const urlObj = new URL(url);
  urlObj.username = "";
  urlObj.password = "";
  return urlObj.href;
}
var ipfsURLPrefix = "ipfs://";
var getJsonLdDocLoader = (ipfsNodeURL = void 0, ipfsGatewayURL = void 0) => {
  return async (url) => {
    if (url.startsWith(ipfsURLPrefix)) {
      const ipfsURL = url.slice(ipfsURLPrefix.length);
      return await loadIPFS(ipfsURL, ipfsNodeURL, ipfsGatewayURL);
    }
    const loader = new JsonLDLoader();
    return loader.loadDocument(url, []);
  };
};

// src/lib/options.ts
function getHasher(opts) {
  return opts?.hasher ?? DEFAULT_HASHER;
}
function getDocumentLoader(opts) {
  return opts?.documentLoader ?? getJsonLdDocLoader(opts?.ipfsNodeURL, opts?.ipfsGatewayURL);
}

// src/lib/rdf-dataset.ts
var RDFDataset = class _RDFDataset {
  constructor(graphs = /* @__PURE__ */ new Map()) {
    this.graphs = graphs;
  }
  // assert consistency of dataset and validate that only
  // quads we support contains in dataset.
  static assertDatasetConsistency = (ds) => {
    for (const [graph, quads] of ds.graphs) {
      for (const q of quads) {
        if (!graph) {
          throw new Error("empty graph name");
        }
        if (graph === MerklizationConstants.DEFAULT_GRAPH_NODE_NAME && q.graph.id) {
          throw new Error("graph should be nil for @default graph");
        }
        if (!q.graph.id && graph !== MerklizationConstants.DEFAULT_GRAPH_NODE_NAME) {
          throw new Error("graph should not be nil for non-@default graph");
        }
      }
    }
  };
  static async fromDocument(doc, documentLoader = getDocumentLoader()) {
    const normalizedData = await canonize(doc, {
      format: MerklizationConstants.QUADS_FORMAT,
      documentLoader
    });
    const parser = new Parser({ format: MerklizationConstants.QUADS_FORMAT });
    const quads = parser.parse(normalizedData);
    const ds = new _RDFDataset();
    for (const q of quads) {
      const graphName = q.graph.termType === MerklizationConstants.DEFAULT_GRAPH_TERM_TYPE ? MerklizationConstants.DEFAULT_GRAPH_NODE_NAME : q.graph.value;
      const graphQuads = ds.graphs.get(graphName) ?? [];
      graphQuads.push(q);
      ds.graphs.set(graphName, graphQuads);
    }
    return ds;
  }
  static getQuad(ds, idx) {
    const quads = ds.graphs.get(idx.graphName);
    if (!quads) {
      throw MerklizationConstants.ERRORS.GRAPH_NOT_FOUND;
    }
    if (idx.idx >= quads.length) {
      throw MerklizationConstants.ERRORS.QUAD_NOT_FOUND;
    }
    return quads[idx.idx];
  }
  static iterGraphsOrdered(ds, callback) {
    const graphNames = [];
    for (const graphName of ds.graphs.keys()) {
      graphNames.push(graphName);
    }
    graphNames.sort((a, b) => a.localeCompare(b));
    for (const graphName of graphNames) {
      const quads = ds.graphs.get(graphName);
      if (!quads) {
        continue;
      }
      callback(graphName, quads);
    }
  }
  static findParent(ds, q) {
    const parent = _RDFDataset.findParentInsideGraph(ds, q);
    if (parent) {
      return parent;
    }
    return _RDFDataset.findGraphParent(ds, q);
  }
  static findParentInsideGraph(ds, q) {
    const graphName = getGraphName(q);
    let result;
    const quads = ds.graphs.get(graphName);
    if (!quads) {
      return void 0;
    }
    const qKey = RefTp.getRefFromQuad(q.subject);
    if (qKey.tp === "Undefined" /* Undefined */) {
      return void 0;
    }
    let found = false;
    for (let idx = 0; idx < quads.length; idx++) {
      const quad = quads[idx];
      if (quad.equals(q)) {
        continue;
      }
      const objKey = RefTp.getRefFromQuad(quad.object);
      if (objKey.tp === "Undefined" /* Undefined */) {
        continue;
      }
      if (qKey?.tp === objKey?.tp && qKey?.val === objKey?.val) {
        if (found) {
          throw MerklizationConstants.ERRORS.MULTIPLE_PARENTS_FOUND;
        }
        found = true;
        result = new DatasetIdx(graphName, idx);
      }
    }
    return result;
  }
  static findGraphParent(ds, q) {
    if (!q.graph) {
      return void 0;
    }
    const qKey = RefTp.getRefFromQuad(q.graph);
    if (qKey.tp === "Undefined" /* Undefined */) {
      return void 0;
    }
    if (qKey.tp !== "BlankNode" /* BlankNode */) {
      throw new Error("graph parent can only be a blank node");
    }
    let found = false;
    let result;
    for (const [graphName, quads] of ds.graphs) {
      for (let idx = 0; idx < quads.length; idx++) {
        const quad = quads[idx];
        if (quad.equals(q)) {
          continue;
        }
        const objKey = RefTp.getRefFromQuad(quad.object);
        if (objKey.tp === "Undefined" /* Undefined */) {
          continue;
        }
        if (qKey.toString() == objKey.toString()) {
          if (found) {
            throw MerklizationConstants.ERRORS.MULTIPLE_PARENTS_FOUND;
          }
          found = true;
          result = new DatasetIdx(graphName, idx);
        }
      }
    }
    if (found) {
      return result;
    }
    throw MerklizationConstants.ERRORS.PARENT_NOT_FOUND;
  }
};

// src/lib/merkle-tree.ts
import { InMemoryDB, str2Bytes } from "@iden3/js-merkletree";
var getMerkleTreeInitParam = (prefix = "", writable = true, maxLevels = 40) => {
  return {
    db: new InMemoryDB(str2Bytes(prefix)),
    writable,
    maxLevels
  };
};
var addEntriesToMerkleTree = async (mt, entries) => {
  for (const e of entries) {
    const { k, v } = await e.getKeyValueMTEntry();
    await mt.add(k, v);
  }
};

// src/lib/path.ts
import { processContext } from "jsonld";
var Path = class _Path {
  constructor(parts = [], hasher = DEFAULT_HASHER) {
    this.parts = parts;
    this.hasher = hasher;
  }
  reverse() {
    return this.parts.reverse();
  }
  append(p) {
    this.parts = [...this.parts, ...p];
  }
  prepend(p) {
    this.parts = [...p, ...this.parts];
  }
  async mtEntry() {
    const h = this.hasher ?? DEFAULT_HASHER;
    const keyParts = new Array(this.parts.length).fill(BigInt(0));
    for (let i = 0; i < this.parts.length; i += 1) {
      const p = this.parts[i];
      if (typeof p === "string") {
        const b = byteEncoder.encode(p);
        keyParts[i] = await h.hashBytes(b);
      } else if (typeof p === "number") {
        keyParts[i] = BigInt(p);
      } else {
        throw new Error(`error: unexpected type ${typeof p}`);
      }
    }
    return h.hash(keyParts);
  }
  async pathFromContext(docStr, path, opts) {
    const doc = JSON.parse(docStr);
    if (!doc["@context"]) {
      throw MerklizationConstants.ERRORS.CONTEXT_NOT_DEFINED;
    }
    const jsonldOpts = { documentLoader: getDocumentLoader(opts) };
    const emptyCtx = await processContext(null, null, jsonldOpts);
    let parsedCtx = await processContext(emptyCtx, doc, jsonldOpts);
    const parts = path.split(".");
    for (const i in parts) {
      const p = parts[i];
      if (MerklizationConstants.DIGITS_ONLY_REGEX.test(p)) {
        this.parts.push(parseInt(p));
      } else {
        const m = parsedCtx.mappings.get(p);
        if (typeof m !== "object") {
          throw MerklizationConstants.ERRORS.TERM_IS_NOT_DEFINED;
        }
        const id = m["@id"];
        if (!id) {
          throw MerklizationConstants.ERRORS.NO_ID_ATTR;
        }
        const nextCtx = m["@context"];
        if (nextCtx) {
          parsedCtx = await processContext(parsedCtx, m, jsonldOpts);
        }
        this.parts.push(id);
      }
    }
  }
  async typeFromContext(ctxStr, path, opts) {
    const ctxObj = JSON.parse(ctxStr);
    if (!("@context" in ctxObj)) {
      throw MerklizationConstants.ERRORS.PARSED_CONTEXT_IS_NULL;
    }
    const jsonldOpts = { documentLoader: getDocumentLoader(opts) };
    const emptyCtx = await processContext(null, null, jsonldOpts);
    let parsedCtx = await processContext(emptyCtx, ctxObj, jsonldOpts);
    const parts = path.split(".");
    for (const i in parts) {
      const p = parts[i];
      const expP = expandType(parsedCtx, p);
      if (expP.hasContext) {
        parsedCtx = await processContext(parsedCtx, expP.typeDef, jsonldOpts);
      }
      this.parts.push(expP["@id"]);
    }
    return _Path.getTypeMapping(parsedCtx, parts[parts.length - 1]);
  }
  static getTypeMapping(ctx, prop) {
    let rval = "";
    const defaultT = ctx.mappings.get("@type");
    if (defaultT) {
      rval = defaultT;
    }
    const propDef = ctx.mappings.get(prop);
    if (propDef && propDef["@type"]) {
      rval = propDef["@type"];
    }
    return rval;
  }
  static newPath = (parts) => {
    const p = new _Path();
    p.append(parts);
    return p;
  };
  static async pathFromDocument(ldCTX, doc, pathParts, acceptArray, opts) {
    if (pathParts.length === 0) {
      return [];
    }
    const term = pathParts[0];
    const newPathParts = pathParts.slice(1);
    const jsonldOpts = { documentLoader: getDocumentLoader(opts) };
    if (MerklizationConstants.DIGITS_ONLY_REGEX.test(term)) {
      const num = parseInt(term);
      const moreParts2 = await _Path.pathFromDocument(ldCTX, doc, newPathParts, true, opts);
      return [num, ...moreParts2];
    }
    if (typeof doc !== "object") {
      throw new Error(`error: expected type object got ${typeof doc}`);
    }
    if (Array.isArray(doc)) {
      if (!doc.length) {
        throw new Error("error: can't generate path on zero-sized array");
      }
      if (!acceptArray) {
        throw MerklizationConstants.ERRORS.UNEXPECTED_ARR_ELEMENT;
      }
      return _Path.pathFromDocument(ldCTX, doc[0], pathParts, false, opts);
    }
    if ("@context" in doc) {
      if (ldCTX) {
        ldCTX = await processContext(ldCTX, doc, jsonldOpts);
      } else {
        const emptyCtx = await processContext(null, null, jsonldOpts);
        ldCTX = await processContext(emptyCtx, doc, jsonldOpts);
      }
    }
    const elemKeys = sortArr(Object.keys(doc));
    const typedScopedCtx = ldCTX;
    for (const k in elemKeys) {
      const key = elemKeys[k];
      if (key !== "@type") {
        const keyCtx = ldCTX?.mappings.get(key);
        if (typeof keyCtx !== "object") {
          continue;
        }
        if (keyCtx["@id"] !== "@type") {
          continue;
        }
      }
      let types = [];
      const docKey = doc[key];
      if (Array.isArray(docKey)) {
        docKey.forEach((e) => {
          if (typeof e !== "string") {
            throw new Error(`error: @type value must be an array of strings: ${typeof e}`);
          }
          types.push(e);
          types = sortArr(types);
        });
      } else if (typeof docKey === "string") {
        types.push(docKey);
      } else {
        throw new Error(`error: unexpected @type field type: ${typeof docKey}`);
      }
      for (const tt of types) {
        const td = typedScopedCtx?.mappings.get(tt);
        if (typeof td === "object" && "@context" in td) {
          ldCTX = await processContext(ldCTX, td, jsonldOpts);
        }
      }
      break;
    }
    const expTerm = expandType(ldCTX, term);
    if (expTerm.hasContext) {
      if (ldCTX) {
        ldCTX = await processContext(ldCTX, expTerm.typeDef, jsonldOpts);
      } else {
        const emptyCtx = await processContext(null, null, jsonldOpts);
        ldCTX = await processContext(emptyCtx, expTerm.typeDef, jsonldOpts);
      }
    }
    const moreParts = await _Path.pathFromDocument(
      ldCTX,
      doc[term],
      newPathParts,
      true,
      opts
    );
    return [expTerm["@id"], ...moreParts];
  }
  static async newPathFromCtx(docStr, path, opts) {
    const p = new _Path([], getHasher(opts));
    await p.pathFromContext(docStr, path, opts);
    return p;
  }
  static getContextPathKey = async (docStr, ctxTyp, fieldPath, opts) => {
    if (ctxTyp === "") {
      throw MerklizationConstants.ERRORS.CTX_TYP_IS_EMPTY;
    }
    if (fieldPath === "") {
      throw MerklizationConstants.ERRORS.FIELD_PATH_IS_EMPTY;
    }
    const fullPath = await _Path.newPathFromCtx(docStr, `${ctxTyp}.${fieldPath}`, opts);
    const typePath = await _Path.newPathFromCtx(docStr, ctxTyp, opts);
    return new _Path(fullPath.parts.slice(typePath.parts.length));
  };
  static async fromDocument(ldCTX, docStr, path, opts) {
    const doc = JSON.parse(docStr);
    const pathParts = path.split(".");
    if (pathParts.length === 0) {
      throw MerklizationConstants.ERRORS.FIELD_PATH_IS_EMPTY;
    }
    const p = await _Path.pathFromDocument(ldCTX, doc, pathParts, false, opts);
    return new _Path(p, getHasher(opts));
  }
  static async newTypeFromContext(contextStr, path, opts) {
    const p = new _Path([], getHasher(opts));
    return await p.typeFromContext(contextStr, path, opts);
  }
  static async getTypeIDFromContext(ctxStr, typeName, opts) {
    const ctxObj = JSON.parse(ctxStr);
    const jsonldOpts = { documentLoader: getDocumentLoader(opts) };
    const emptyCtx = await processContext(null, null, jsonldOpts);
    const parsedCtx = await processContext(emptyCtx, ctxObj, jsonldOpts);
    const typeDef = parsedCtx.mappings.get(typeName);
    if (!typeDef) {
      throw new Error(`looks like ${typeName} is not a type`);
    }
    const typeID = typeDef["@id"];
    if (!typeID) {
      throw new Error(`@id attribute is not found for type ${typeName}`);
    }
    if (typeof typeID !== "string") {
      throw new Error(`@id attribute is not a string for type ${typeName}`);
    }
    return typeID;
  }
};
function expandType(ctx, term) {
  const m = ctx?.mappings.get(term);
  if (typeof m !== "object") {
    throw MerklizationConstants.ERRORS.TERM_IS_NOT_DEFINED;
  }
  const id = m["@id"];
  if (!id) {
    throw MerklizationConstants.ERRORS.NO_ID_ATTR;
  }
  if (typeof id !== "string") {
    throw new Error(`error: @id attr is not of type string: ${typeof id}`);
  }
  return {
    "@id": id,
    hasContext: "@context" in m,
    typeDef: m
  };
}

// src/lib/quad-arr-key.ts
var QuadArrKey = class _QuadArrKey {
  subject;
  predicate;
  graph;
  constructor(q) {
    this.graph = getGraphName(q);
    const s = q.subject;
    switch (s.termType) {
      case "NamedNode" /* IRI */:
        this.subject = { tp: "NamedNode" /* IRI */, val: s.value };
        break;
      case "BlankNode" /* BlankNode */:
        this.subject = { tp: "BlankNode" /* BlankNode */, val: s.value };
        break;
      default:
        throw new Error("invalid subject type");
    }
    if (q.predicate.termType !== "NamedNode" /* IRI */) {
      throw new Error("invalid predicate type");
    }
    this.predicate = q.predicate.value;
  }
  toString() {
    return JSON.stringify(this);
  }
  static countEntries = (nodes) => {
    const res = /* @__PURE__ */ new Map();
    for (const q of nodes) {
      const key = new _QuadArrKey(q);
      let c = res.get(key.toString()) ?? 0;
      res.set(key.toString(), ++c);
    }
    return res;
  };
};

// src/lib/relationship.ts
var Relationship = class _Relationship {
  constructor(parents = /* @__PURE__ */ new Map(), children = /* @__PURE__ */ new Map(), hasher = DEFAULT_HASHER) {
    this.parents = parents;
    this.children = children;
    this.hasher = hasher;
  }
  static getIriValue(n) {
    if (n.predicate.termType === "NamedNode" /* IRI */) {
      return n.predicate.value;
    }
    throw new Error("type is not IRI");
  }
  path(dsIdx, ds, idx) {
    const k = new Path([], this.hasher);
    if (typeof idx === "number") {
      k.append([idx]);
    }
    const n = RDFDataset.getQuad(ds, dsIdx);
    const predicate = _Relationship.getIriValue(n);
    k.append([predicate]);
    let nextKey = dsIdx;
    for (; ; ) {
      const parentIdx = this.parents.get(nextKey.toString());
      if (!parentIdx) {
        break;
      }
      const parent = RDFDataset.getQuad(ds, parentIdx);
      const parentKey = new QuadArrKey(parent);
      const childrenMap = this.children.get(parentKey.toString());
      if (!childrenMap) {
        throw new Error("parent mapping not found");
      }
      const childQuad = RDFDataset.getQuad(ds, nextKey);
      const childRef = RefTp.getRefFromQuad(childQuad.subject);
      const childIdx = childrenMap.get(childRef.toString());
      if (typeof childIdx !== "number") {
        throw new Error("child not found in parents mapping");
      }
      const parentPredicate = _Relationship.getIriValue(parent);
      if (childrenMap.size === 1) {
        k.append([parentPredicate]);
      } else {
        k.append([childIdx, parentPredicate]);
      }
      nextKey = parentIdx;
    }
    k.reverse();
    return k;
  }
  static async newRelationship(ds, hasher) {
    const r = new _Relationship(/* @__PURE__ */ new Map(), /* @__PURE__ */ new Map(), hasher);
    RDFDataset.iterGraphsOrdered(ds, (graphName, quads) => {
      for (let idx = 0; idx < quads.length; idx++) {
        const q = quads[idx];
        const parentIdx = RDFDataset.findParent(ds, q);
        if (!parentIdx) {
          continue;
        }
        const qIdx = new DatasetIdx(graphName, idx);
        r.parents.set(qIdx.toString(), parentIdx);
        const parentQuad = RDFDataset.getQuad(ds, parentIdx);
        const qKey = new QuadArrKey(parentQuad);
        let childrenM = r.children.get(qKey.toString());
        if (!childrenM) {
          childrenM = /* @__PURE__ */ new Map();
          r.children.set(qKey.toString(), childrenM);
        }
        const childRef = RefTp.getRefFromQuad(q.subject);
        const childExists = childrenM.get(childRef.toString());
        if (typeof childExists !== "number") {
          const nextIdx = childrenM.size;
          childrenM.set(childRef.toString(), nextIdx);
        }
      }
    });
    return r;
  }
};

// src/lib/rdf-entry.ts
import { Temporal as Temporal3 } from "@js-temporal/polyfill";
var RDFEntry = class _RDFEntry {
  constructor(key, value, dataType = "", hasher = DEFAULT_HASHER) {
    this.key = key;
    this.value = value;
    this.dataType = dataType;
    this.hasher = hasher;
    if (!key.parts.length) {
      throw new Error("key length is zero");
    }
    validateValue(value);
  }
  getHasher() {
    return this.hasher;
  }
  getKeyMtEntry() {
    return this.key.mtEntry();
  }
  getValueMtEntry() {
    return MtValue.mkValueMtEntry(this.getHasher(), this.value);
  }
  async getKeyValueMTEntry() {
    const k = await this.getKeyMtEntry();
    const v = await this.getValueMtEntry();
    return { k, v };
  }
  static newRDFEntry = (k, v) => {
    const e = new _RDFEntry(k, v);
    switch (typeof v) {
      case "number":
      case "string":
      case "boolean":
        e.value = v;
        break;
      default:
        if (v instanceof Temporal3.Instant) {
          e.value = v;
        } else {
          throw new Error(`error: incorrect value type ${typeof v}`);
        }
    }
    return e;
  };
  static async fromDataSet(ds, hasher = DEFAULT_HASHER) {
    RDFDataset.assertDatasetConsistency(ds);
    const quads = ds.graphs.get(MerklizationConstants.DEFAULT_GRAPH_NODE_NAME);
    if (!quads?.length) {
      throw new Error("@default graph not found in dataset");
    }
    const rs = await Relationship.newRelationship(ds, hasher);
    const entries = [];
    const graphProcessor = (graphName, quads2) => {
      const counts = QuadArrKey.countEntries(quads2);
      const seenCount = /* @__PURE__ */ new Map();
      for (let quadIdx = 0; quadIdx < quads2.length; quadIdx++) {
        let dataType = "";
        const q = quads2[quadIdx];
        const quadGraphIdx = new DatasetIdx(graphName, quadIdx);
        const qKey = new QuadArrKey(q);
        let value;
        const qo = q.object.termType;
        const qoVal = q.object.value;
        switch (qo) {
          case "Literal" /* Literal */:
            dataType = q?.object?.datatype?.value;
            value = convertStringToXsdValue(dataType, qoVal, hasher.prime());
            break;
          case "NamedNode" /* IRI */:
            if (!qo) {
              throw new Error("object IRI is nil");
            }
            value = qoVal;
            break;
          case "BlankNode" /* BlankNode */:
            const p = rs.children.get(qKey.toString());
            if (p) {
              continue;
            }
            throw new Error("BlankNode is not supported yet");
          case "Variable":
            value = qoVal;
            break;
          default:
            throw new Error("unexpected Quad's Object type");
        }
        const count = counts.get(qKey.toString());
        let idx;
        switch (count) {
          case 0:
            throw new Error("[assertion] key not found in counts");
          case 1:
            break;
          default:
            const key = qKey.toString();
            idx = seenCount.get(key) ?? 0;
            seenCount.set(key, idx + 1);
        }
        const path = rs.path(quadGraphIdx, ds, idx);
        const e = new _RDFEntry(path, value, dataType, hasher);
        entries.push(e);
      }
    };
    RDFDataset.iterGraphsOrdered(ds, graphProcessor);
    return entries;
  }
};

// src/lib/merklizer.ts
var Merklizer = class _Merklizer {
  constructor(srcDoc = null, mt = null, hasher = DEFAULT_HASHER, entries = /* @__PURE__ */ new Map(), compacted = null, documentLoader = getDocumentLoader()) {
    this.srcDoc = srcDoc;
    this.mt = mt;
    this.hasher = hasher;
    this.entries = entries;
    this.compacted = compacted;
    this.documentLoader = documentLoader;
    if (!mt) {
      const { db, writable, maxLevels } = getMerkleTreeInitParam();
      this.mt = new Merkletree2(db, writable, maxLevels);
    }
  }
  async proof(p) {
    const kHash = await p.mtEntry();
    if (!this.mt) {
      throw new Error("Merkle tree is not initialized");
    }
    const { proof } = await this.mt.generateProof(kHash);
    if (proof.existence) {
      if (!this.entries.has(kHash.toString())) {
        throw new Error("error: [assertion] no entry found while existence is true");
      }
      const entry = this.entries.get(kHash.toString());
      if (!entry) {
        throw new Error("entry not found");
      }
      const value = new MtValue(entry.value, this.hasher);
      return { proof, value };
    }
    return { proof };
  }
  mkValue(val) {
    return new MtValue(val, this.hasher);
  }
  async resolveDocPath(path, opts) {
    if (!this.srcDoc) {
      throw new Error("Source document is not initialized");
    }
    const realPath = await Path.fromDocument(null, this.srcDoc, path, opts);
    realPath.hasher = this.hasher;
    return realPath;
  }
  async entry(path) {
    const key = await path.mtEntry();
    const e = this.entries.get(key.toString());
    if (!e) {
      throw new Error("entry not found");
    }
    return e;
  }
  // JSONLDType returns the JSON-LD type of the given path. If there is no literal
  // by this path, it returns an error.
  async jsonLDType(path) {
    const entry = await this.entry(path);
    return entry.dataType;
  }
  async root() {
    if (!this.mt) {
      throw new Error("Merkle tree is not initialized");
    }
    return this.mt.root();
  }
  rawValue(path) {
    let parts = path.parts;
    if (!this.compacted) {
      throw new Error("Compact document is not initialized");
    }
    let obj = this.compacted;
    const traversedParts = [];
    const currentPath = () => traversedParts.join(" / ");
    while (parts.length > 0) {
      const p = parts[0];
      if (typeof p === "string") {
        traversedParts.push(p);
        obj = obj[p] ?? (obj["@graph"] ?? {})[p];
        if (!obj) {
          throw new Error("value not found");
        }
      } else if (typeof p === "number") {
        traversedParts.push(p.toString());
        obj = this.rvExtractArrayIdx(obj, p);
      } else {
        throw new Error(`unexpected type of path ${currentPath()}`);
      }
      parts = parts.slice(1);
    }
    if (typeof obj["@value"] !== "undefined") {
      return obj["@value"];
    }
    return obj;
  }
  rvExtractArrayIdx(obj, idx) {
    const isArray = Array.isArray(obj);
    if (!isArray) {
      throw new Error("expected array");
    }
    if (idx < 0 || idx >= obj.length) {
      throw new Error("index is out of range");
    }
    return obj[idx];
  }
  static async merklizeJSONLD(docStr, opts) {
    const hasher = getHasher(opts);
    const documentLoader = getDocumentLoader(opts);
    const mz = new _Merklizer(docStr, null, hasher, /* @__PURE__ */ new Map(), null, documentLoader);
    if (!mz) {
      throw new Error("Merklizer is not initialized");
    }
    if (!mz.srcDoc) {
      throw new Error("Source document is not initialized");
    }
    const doc = JSON.parse(mz.srcDoc);
    const dataset = await RDFDataset.fromDocument(doc, documentLoader);
    const entries = await RDFEntry.fromDataSet(dataset, hasher);
    for (const e of entries) {
      const k = await e.getKeyMtEntry();
      mz.entries.set(k.toString(), e);
    }
    if (!mz.mt) {
      throw new Error("Merkle tree is not initialized");
    }
    await addEntriesToMerkleTree(mz.mt, entries);
    mz.compacted = await compact(
      doc,
      {},
      {
        documentLoader,
        base: null,
        compactArrays: true,
        compactToRelative: true
      }
    );
    return mz;
  }
  static async hashValue(dataType, value) {
    return this.hashValueWithHasher(DEFAULT_HASHER, dataType, value);
  }
  static async hashValueWithHasher(h, dataType, value) {
    const valueStr = convertAnyToString(value, dataType);
    const xsdValue = convertStringToXsdValue(dataType, valueStr, h.prime());
    return await MtValue.mkValueMtEntry(h, xsdValue);
  }
  get options() {
    return {
      hasher: this.hasher,
      documentLoader: this.documentLoader
    };
  }
};

// src/index.ts
import { Temporal as Temporal4 } from "@js-temporal/polyfill";
export {
  MerklizationConstants,
  Merklizer,
  MtValue,
  Path,
  PoseidonHasher,
  Temporal4 as Temporal,
  getDocumentLoader
};
//# sourceMappingURL=index.js.map
